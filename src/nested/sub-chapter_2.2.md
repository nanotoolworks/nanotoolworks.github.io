# Chapter 2 -- The 50-Day Plan For Building A Personal Assistant Agentic System (PAAS)

## PHASE 1: FOUNDATIONS (Days 1-10)

### Day 3-4: Understanding Basic Organization Structure For Developing Agentic Systems & Large Language Models

During these two days, you will focus on building a comprehensive understanding of is necessary to develop agentic systems which goes beyond just how the system work but how the systems are developed. It is mostly about project management and organization, but with particular emphasis on how LLMs will be used and what kinds of things need to be in place as foundation for their develop. You will explore everything that you can how modern LLMs function, what capabilities they offer for creating autonomous agents, and what architectural patterns have proven most effective in research. You will need to identify the key limitations and opportunities for improvement. At first, you will work on the basics, but then move on to how problems were overcome, such as context window constraints and hallucination tendencies. You will need to use your experience on how to prompt LLMs more effectively to get them to reason better through complex tasks in a step-by-step fashion. In the final analysis, your use of AI agents will inform your engineering of systems based on the concepts you have acquired to build better intelligence gathering systems that monitor their own operation and assist in the process of synthesizing information from multiple sources.

**REMINDER** *FIRST thing ... each day ... READ the assignment over carefully*, just to assure you *understand* the day's assignment. You are not required to actually DO that assignment, but you really should try to UNDERSTAND what you are supposed to look over ... REMEMBER: This is not only about programming a PAAS, **you are programming yourself to be an autodidact** so if you want to rip up the script and do it a better way, *go for it...*

- **Morning (3h)**: Study the fundamentals of agentic systems
  Ask your favorite AI to explain things to to you; learn to really USE agentic AI ... push it, ask more questions, SPEEDREAD or even skim what it has produced and ask more and more questions. Immerse yourself in dialogue with agentic systems, particularly in learning more about the following key concepts of agentic systems:
  - **LLM capabilities and limitations:** Examine the core capabilities of LLMs like Claude and GPT-4 or the latest/greatest/hottest trending LLM, focusing on their reasoning abilities, knowledge limitations, and how context windows constrain what they can process at once. Deep into various techniques that different people are tweeting, blogging, discussion on things like prompt engineering, chain-of-thought prompting, and retrieval augmentation that help overcome these limitations. Take note of what perplexes you as you come across it and use your AI assistant to explain it to you ... use the answers to help you ***curate your own reading lists of important matter on LLM capabilities and limitations.***
  - **[Agent architecture patterns](https://arxiv.org/search/?query=Agent+architecture+patterns&searchtype=all&source=header)** ([ReAct](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation), Plan-and-Execute, Self-critique): Learn the standard patterns for building LLM-based agents, understanding how ReAct combines reasoning and action in a loop, how Plan-and-Execute separates planning from execution, and how self-critique mechanisms allow agents to improve their outputs. Focus on identifying which patterns will work best for continuous intelligence gathering and summarization tasks. Develop curating reading lists of blogs like the [LangChain.Dev Blog](https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/) in order to follow newsy topics like [Top 5 LangGraph Agents in Production 2024](https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/) or [agent case studies](https://blog.langchain.dev/tag/case-studies/)
  - [**Develop your skimming, sorting, speedreading capabilities for key papers on Computatation and Language**](https://arxiv.org/list/cs.CL/recent): [Chain-of-Thought](https://arxiv.org/search/?query=Chain-of-Thought&searchtype=all&source=header), [Tree of Thoughts](https://arxiv.org/search/?query=Tree+of+Thoughts&searchtype=all&source=header), [ReAct](https://arxiv.org/search/?query=React+Agent+LLM&searchtype=all&abstracts=show&order=-announced_date_first&size=200): Use a tool, [such as ConnectedPapers](https://www.connectedpapers.com/main/1c8871c4126a4855ac96c1b29fb06d012f56feb5/Autono%3A-A-ReAct%20Based-Highly-Robust-Autonomous-Agent-Framework/graph) to understand the knowledge graphs of these papers; as you ***USE*** the knowledge graph tool, think about how you would like to see it built better ... *that kind of capability is kind of the point of learning to dev automated intelligence gathering PAAS*. You will want to examine the structure of the knowledge landscape, until you can identify the foundational seminal papers and intuitively understand the direction of research behind modern agent approaches, taking detailed notes on their methodologies and results. Implement simple examples of each approach using Python and an LLM API to solidify your understanding of how they work in practice.

- **Afternoon (3h)**: Research and begin to set up development environments
  - **Install necessary Python libraries (transformers, langchain, etc.) LOCALLY**: Compare/contrast the Pythonic approach with the Rust language approach from Day 1-2; there's certainly a lot to admire about Python, ***but there's also a reason to use Rust!*** You need to really ***understand*** the strengths of the Pythonic approach, before you reinvent the wheel in Rust. There's room for both languages and will be for some time. Set up several Python virtual environments and teach yourself how to rapidly install the essential packages like LangChain, transformers, and relevant API clients you'll need in these different environments. You might have favorites, but you will be using multiple Python environments throughout the project. 
  - **Research the realm of LLM tools vs LLM Ops platforms used to build, test, and monitor large language model (LLM) applications**: LLM tools are for the technical aspects of model development, such as training, fine-tuning, and deployment of LLM applications. LLMOps are for operational practices of running LLM applications including tools that deploy, monitor, and maintain these models in production environments. You will ultimately use both, but that time you will focus on LLM tools, including HuggingFace, GCP Vertex, [MLflow](https://mlflow.org/docs/latest/index.html), [LangSmith](https://docs.smith.langchain.com/), [LangFuse](https://langfuse.com/), [LlamaIndex](https://www.llamaindex.ai/), [DeepSetAI](https://www.deepset.ai/)  Understand the [general concepts related to managing users, organizations, and workspaces within a platforms like LangSmith](https://docs.smith.langchain.com/administration/concepts); these concepts will be similar to, but perhaps not identical to those you would use for the other platforms you might use to build, test, and monitor large language model (LLM) applications ... you will want to be thinking about your strategies for things like configure your API keys for LLM services (OpenAI, Antropic, et al) you plan to use, [ensuring your credentials are stored securely.](https://www.strac.io/blog/sharing-and-storing-api-keys-securely)
  - **Research cloud GPU resources and start thinking about how you will set up these items:** At this point, this is entirely a matter of research, not actually setting up resources but you will want to look at how that is accomplished. At this point, you will asking lots of questions and evaluating the quality of the documentation/support available, before dabbling a weensy little bit. You will need to be well-informed in order to begin determining what kind of cloud computing resources are relevant for your purposes and which will will be most relevant for you to evalate when you need the computational power for more intensive tasks, considering options like RunPod, ThunderCompute, VAST.AI or others or maybe the AWS, GCP, or Azure for hosting your system. Understand the billing first of all, then research the processes for create accounts and setting up basic infrastructure ... you will want to understand how this is done BEFORE YOU NEED TO DO IT. At some point, when you are ready, you can move forward knowledgably, understanding the alternatives to ensure that you can most efficiently go about programmatically accessing only those cloud services you actually require.
  - **Create an organization project structure for your repositories:** Establish a GitHub organizattion in order to ORGANIZE your project repositories with some semblance of a clear structure for your codebase, including repositories for important side projects and multi-branch repositories with branches/directories for each major component. You may wish to secure a domain name and forward it to this organization, but that is entirely optional. You will want to completely immerse yourself in the GitHub approach to doing everything, including how to manage an organization. You will want to review the best practices for things like create comprehensive READMEs which outlines the repository goals, setup instructions and contribution guidelines. You will also want to exploit all of GitHub features for  discussions, issues, wikis, development roadmaps. You may want to set up onboarding repositories for training / instructions intended for volunteers who might join your organization.
